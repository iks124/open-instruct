## 实验设计

### 实验 1：模型尺寸、数据量与提升精度的关系

| **实验目标** | 探讨不同尺寸模型（1.5b, 7b）在不同数据量（1K, 2K, 5K, 10K, 17K）下的精度提升。 |
| ------------------ | ------------------------------------------------------------------------------ |
| **数据集**   | GSM8K 和 MATH 对齐混合数据集。                                                 |
| **数据量**   | 1K, 2K, 5K, 10K, 17K（随机采样，期望对半分）。                                 |
| **模型**     | 1.5b 和 7b 模型（base）。                                                      |
| **评估**     | 训练前后在 GSM8K 和 MATH 上的精度。                                            |

---

### 实验 2：数据增强与精度提升

| **实验目标** | 通过数据增强（如问题表述形式调整、新问题生成等）提升模型精度。 |
| ------------------ | -------------------------------------------------------------- |
| **数据集**   | 基于 GSM8K 和 MATH 的数据增强（参考 MetaMath 的方法）。        |
| **模型**     | 实验 1 中表现较好的 7b模型。                                   |
| **数据量**   | 在实验 1 的基础上，使用增强数据集继续优化。                    |
| **评估**     | 训练前后在 GSM8K 和 MATH 上的精度，并进行案例分析。            |

---

### 实验参数设置

| **参数**                        | **说明**                       |
| ------------------------------------- | ------------------------------------ |
| **epoch**                       | 1~3 个 epoch。                       |
| **gradient_accumulation_steps** | 尝试 16 / 32 / 64 / 128 等值。       |
| **global_batch_size**           | Negatron 的参数，Despspect 可无视。  |
| **learning_rate**               | 小模型用大学习率，大模型用小学习率。 |
| **lr_scheduler_type**           | 尝试几种主流的 lr_scheduler。        |
| **dropout**                     | 根据模型大小和训练稳定性调整。       |
| **zero_stage**                  | 影响训练速度，需根据硬件配置调整。   |
| **max_seq_len**                 | 设置合理的序列长度。                 |
| **offload**                     | 是否启用 offload 功能。              |
| **gradient_checkpointing**      | 是否启用梯度检查点以节省显存。       |
| **seq_parallel_size**           | 序列并行大小，影响训练效率。         |
| **weight_decay**                | 对模型训练影响较小，但需了解其意义。 |
| **per_device_train_batch_size** | 每个设备的训练批次大小。             |
| **num_warmup_steps**            | 起始训练时适当做点 warmup。          |

---

### 注意事项

1. **数据集**：

   - 使用 GSM8K 和 MATH 作为基础数据集。
   - 数据增强方法包括问题表述形式调整、新问题生成等。
2. **模型**：

   - 1.5b 和 7b 模型（base）。
   - 训练时注意 special token 的设置，instruct 模型需参照原文的 chat_template。
3. **训练技巧**：

   - 小模型用大学习率，大模型用小学习率。
   - 起始训练时适当做点 warmup。
   - 尝试不同的 gradient_accumulation_steps 值（16 / 32 / 64 / 128）。
4. **评估**：

   - 训练前后在 GSM8K 和 MATH 上的精度。
   - 进行案例分析，了解训练后模型的表现。

---

### 总结

- **实验 1** 旨在探讨模型尺寸与数据量的关系，为后续实验提供基础。
- **实验 2** 通过数据增强进一步提升模型精度。
- **参数设置** 对训练速度和模型性能有重要影响，需根据实际情况调整。
